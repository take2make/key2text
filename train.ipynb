{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration,Adafactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=pd.read_csv('webNLG2020_train.csv', index_col=[0])\n",
    "train_df=train_df.iloc[  :35000,:]\n",
    "train_df=train_df.sample(frac = 1)\n",
    "batch_size=8\n",
    "num_of_batches=int(len(train_df)/batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    dev = torch.device(\"cuda:0\")\n",
    "    print(\"Running on the GPU\")\n",
    "else:\n",
    "    dev = torch.device(\"cpu\")\n",
    "    print(\"Running on the CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained('t5-base')\n",
    "model = T5ForConditionalGeneration.from_pretrained('t5-base',\n",
    "                                             return_dict=True)\n",
    "#moving the model to GPU\n",
    "model.to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adafactor(model.parameters(),lr=1e-3,\n",
    "                      eps=(1e-30, 1e-3),\n",
    "                      clip_threshold=1.0,\n",
    "                      decay_rate=-0.8,\n",
    "                      beta1=None,\n",
    "                      weight_decay=0.0,\n",
    "                      relative_step=False,\n",
    "                      scale_parameter=False,\n",
    "                      warmup_init=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML, display\n",
    "def progress(loss,value, max=100):\n",
    "    return HTML(\"\"\" Batch loss :{loss}\n",
    "      <progress    \n",
    "value='{value}'max='{max}',style='width: 100%'>{value}\n",
    "      </progress>\n",
    "             \"\"\".format(loss=loss,value=value, max=max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sets the module in training mode\n",
    "model.train()\n",
    "num_of_epochs = 3\n",
    "\n",
    "loss_per_10_steps=[]\n",
    "for epoch in range(1,num_of_epochs+1):\n",
    "    print('Running epoch: {}'.format(epoch))\n",
    "  \n",
    "    running_loss=0\n",
    "\n",
    "    out = display(progress(1, num_of_batches+1), display_id=True)\n",
    "    for i in range(num_of_batches):\n",
    "        inputbatch=[]\n",
    "        labelbatch=[]\n",
    "        new_df=train_df[i*batch_size:i*batch_size+batch_size]\n",
    "        for indx,row in new_df.iterrows():\n",
    "            input = 'WebNLG: '+row['input_text']+'</s>' \n",
    "            labels = row['target_text']+'</s>'   \n",
    "            inputbatch.append(input)\n",
    "            labelbatch.append(labels)\n",
    "        inputbatch=tokenizer.batch_encode_plus(inputbatch,padding=True,max_length=400,return_tensors='pt')[\"input_ids\"]\n",
    "        labelbatch=tokenizer.batch_encode_plus(labelbatch,padding=True,max_length=400,return_tensors=\"pt\") [\"input_ids\"]\n",
    "        inputbatch=inputbatch.to(dev)\n",
    "        labelbatch=labelbatch.to(dev)\n",
    "\n",
    "        # clear out the gradients of all Variables \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward propogation\n",
    "        outputs = model(input_ids=inputbatch, labels=labelbatch)\n",
    "        loss = outputs.loss\n",
    "        loss_num=loss.item()\n",
    "        logits = outputs.logits\n",
    "        running_loss+=loss_num\n",
    "        if i%10 ==0:      \n",
    "            loss_per_10_steps.append(loss_num)\n",
    "        out.update(progress(loss_num,i, num_of_batches+1))\n",
    "\n",
    "        # calculating the gradients\n",
    "        loss.backward()\n",
    "\n",
    "        #updating the params\n",
    "        optimizer.step()\n",
    "    \n",
    "    running_loss=running_loss/int(num_of_batches)\n",
    "    print('Epoch: {} , Running loss: {}'.format(epoch,running_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),'trained_model/pytorch_model.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained('t5-base')\n",
    "model = T5ForConditionalGeneration.from_pretrained('trained_model', \n",
    "                                                return_dict=True)\n",
    "import re\n",
    "\n",
    "def generate(text):\n",
    "    texts = text.split(\".\")\n",
    "    result = \"\"\n",
    "    for txt in texts:\n",
    "        model.eval()\n",
    "        input_ids = tokenizer.encode(\"WebNLG:{} </s>\".format(txt), \n",
    "                                   return_tensors=\"pt\")  \n",
    "        outputs = model.generate(input_ids)\n",
    "        result += tokenizer.decode(outputs[0])\n",
    "    result = re.sub('<pad>|</s>',\"\",result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
