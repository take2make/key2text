{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration,Adafactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=pd.read_csv('webNLG2020_train.csv', index_col=[0])\n",
    "train_df=train_df.iloc[  :35000,:]\n",
    "train_df=train_df.sample(frac = 1)\n",
    "batch_size=8\n",
    "num_of_batches=int(len(train_df)/batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4375"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_of_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prefix</th>\n",
       "      <th>input_text</th>\n",
       "      <th>target_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21864</th>\n",
       "      <td>webNLG</td>\n",
       "      <td>Bananaman | starring | Tim_Brooke-Taylor &amp;&amp; Ba...</td>\n",
       "      <td>The BBC began broadcasting Bananaman on 10/03/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29613</th>\n",
       "      <td>webNLG</td>\n",
       "      <td>14th_New_Jersey_Volunteer_Infantry_Monument | ...</td>\n",
       "      <td>The 14th New Jersey Volunteer Infantry Monumen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32543</th>\n",
       "      <td>webNLG</td>\n",
       "      <td>Aleksandra_Kovač | associatedBand/associatedMu...</td>\n",
       "      <td>Aleksandra Kovac has the musical genre of pop ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30958</th>\n",
       "      <td>webNLG</td>\n",
       "      <td>AIDAstella | christeningDate | 2013-03-16 &amp;&amp; A...</td>\n",
       "      <td>The christening date of AIDAstella is 2013-03-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8431</th>\n",
       "      <td>webNLG</td>\n",
       "      <td>11264_Claudiomaccone | averageSpeed | 18.29 (k...</td>\n",
       "      <td>Nikolai Chernykh discovered 11264 Claudiomacco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4593</th>\n",
       "      <td>webNLG</td>\n",
       "      <td>Serie_A | champions | Juventus_F.C.</td>\n",
       "      <td>Juventus F.C. are former champions of Serie A.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19044</th>\n",
       "      <td>webNLG</td>\n",
       "      <td>Albennie_Jones | genre | Jazz &amp;&amp; Albennie_Jone...</td>\n",
       "      <td>Albennie Jones is a solo singer and performs j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21172</th>\n",
       "      <td>webNLG</td>\n",
       "      <td>Akeem_Priestley | club | Sheikh_Russel_KC &amp;&amp; A...</td>\n",
       "      <td>Akeem Priestley's club is Harbour View F.C and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34426</th>\n",
       "      <td>webNLG</td>\n",
       "      <td>AFC_Ajax_(amateurs) | ground | Sportpark_De_To...</td>\n",
       "      <td>AFC Ajax (amateurs)'s ground is Sportpark De T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3663</th>\n",
       "      <td>webNLG</td>\n",
       "      <td>Antares_(rocket) | finalFlight | 2014-07-13</td>\n",
       "      <td>The final flight for the rocket Antares was on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27404</th>\n",
       "      <td>webNLG</td>\n",
       "      <td>Elliot_See | status | \"Deceased\" &amp;&amp; Elliot_See...</td>\n",
       "      <td>The American test pilot Elliot See was born in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25003</th>\n",
       "      <td>webNLG</td>\n",
       "      <td>Alligator_Records | location | Chicago &amp;&amp; Ande...</td>\n",
       "      <td>Anders Osborne is a rock musician associated w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5315</th>\n",
       "      <td>webNLG</td>\n",
       "      <td>Ícolo_e_Bengo | country | Angola</td>\n",
       "      <td>Ícolo e Bengo is in Angola.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>webNLG</td>\n",
       "      <td>Arem-arem | course | \"Main course\"</td>\n",
       "      <td>Arem arem is a main course.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27736</th>\n",
       "      <td>webNLG</td>\n",
       "      <td>300_North_LaSalle | location | Chicago &amp;&amp; Chic...</td>\n",
       "      <td>Located in the United States is 300 North LaSa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3130</th>\n",
       "      <td>webNLG</td>\n",
       "      <td>Aenir | followedBy | Above_the_Veil</td>\n",
       "      <td>The book Aenir was followed up by Above the Veil.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7474</th>\n",
       "      <td>webNLG</td>\n",
       "      <td>103_Colmore_Row | architect | John_Madin &amp;&amp; 10...</td>\n",
       "      <td>John Madin was the architect of 103 Colmore Ro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34687</th>\n",
       "      <td>webNLG</td>\n",
       "      <td>Abner_(footballer) | club | Real_Madrid_Castil...</td>\n",
       "      <td>The footballer Abner was born on 30/05/1996 an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14714</th>\n",
       "      <td>webNLG</td>\n",
       "      <td>3Arena | owner | Live_Nation_Entertainment &amp;&amp; ...</td>\n",
       "      <td>The owner of 3Arena, located at North Wall, Du...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24395</th>\n",
       "      <td>webNLG</td>\n",
       "      <td>Acta_Palaeontologica_Polonica | issnNumber | \"...</td>\n",
       "      <td>Acta Palaeontologica Polonica (abbrv. Acta Pal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24444</th>\n",
       "      <td>webNLG</td>\n",
       "      <td>English_language | spokenIn | Great_Britain &amp;&amp;...</td>\n",
       "      <td>The United States, whose capital is Washington...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11710</th>\n",
       "      <td>webNLG</td>\n",
       "      <td>English_language | spokenIn | Great_Britain &amp;&amp;...</td>\n",
       "      <td>A Loyal Character Dancer is published in the U...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16967</th>\n",
       "      <td>webNLG</td>\n",
       "      <td>Indiana | capital | Indianapolis &amp;&amp; Alexandria...</td>\n",
       "      <td>Alexandria is located in Indiana where Indiana...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8076</th>\n",
       "      <td>webNLG</td>\n",
       "      <td>Duncan_Rouleau | nationality | Americans &amp;&amp; Ba...</td>\n",
       "      <td>Baymax is a character in the film Big Hero 6 w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34657</th>\n",
       "      <td>webNLG</td>\n",
       "      <td>Abel_Hernández | club | Peñarol &amp;&amp; Peñarol | m...</td>\n",
       "      <td>Abel Hernández has played for U.S. Città di Pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25322</th>\n",
       "      <td>webNLG</td>\n",
       "      <td>Arrabbiata_sauce | country | Italy &amp;&amp; Italy | ...</td>\n",
       "      <td>Italians are from Italy where Pietro Grasso is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10658</th>\n",
       "      <td>webNLG</td>\n",
       "      <td>Saranac_Lake,_New_York | isPartOf | Harrietsto...</td>\n",
       "      <td>Adirondack Regional Airport serves the city of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30968</th>\n",
       "      <td>webNLG</td>\n",
       "      <td>AIDAstella | maidenVoyage | 2013-03-17 &amp;&amp; AIDA...</td>\n",
       "      <td>The AIDAstella was christened on 16th of March...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18583</th>\n",
       "      <td>webNLG</td>\n",
       "      <td>Administrative_Science_Quarterly | abbreviatio...</td>\n",
       "      <td>The ISSN number for Administrative Science Qua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1520</th>\n",
       "      <td>webNLG</td>\n",
       "      <td>Aleksandre_Guruli | club | US_Boulogne</td>\n",
       "      <td>Aleksandre Guruli played for US Boulogne.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18478</th>\n",
       "      <td>webNLG</td>\n",
       "      <td>A_Severed_Wasp | language | English_language &amp;...</td>\n",
       "      <td>A Severed Wasp originates from the United Stat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32719</th>\n",
       "      <td>webNLG</td>\n",
       "      <td>Allen_Forrest | genre | Rhythm_and_blues &amp;&amp; Al...</td>\n",
       "      <td>Born in Fort Campbell, Allen Forrest, is a sol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18562</th>\n",
       "      <td>webNLG</td>\n",
       "      <td>Acta_Palaeontologica_Polonica | publisher | Po...</td>\n",
       "      <td>Acta Palaeontologica Polonica was published by...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15120</th>\n",
       "      <td>webNLG</td>\n",
       "      <td>Bibbo_Bibbowski | creator | Jerry_Ordway &amp;&amp; Bi...</td>\n",
       "      <td>Bo Bibbowski is often called Bibbo and was cre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34263</th>\n",
       "      <td>webNLG</td>\n",
       "      <td>A.D._Isidro_Metapán | ground | \"Metapán, El Sa...</td>\n",
       "      <td>Asociacion Deportiva (abbreviated to A.D. Isid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33923</th>\n",
       "      <td>webNLG</td>\n",
       "      <td>Elliot_See | almaMater | University_of_Texas_a...</td>\n",
       "      <td>Elliot See, who was born in Dallas, attended t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2336</th>\n",
       "      <td>webNLG</td>\n",
       "      <td>Richland_Township,_Madison_County,_Indiana | c...</td>\n",
       "      <td>Richland Township, in Madison County, Indiana ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21263</th>\n",
       "      <td>webNLG</td>\n",
       "      <td>Aleksandr_Chumakov | deathPlace | Moscow &amp;&amp; Mo...</td>\n",
       "      <td>Aleksandr Chumakov passed away in Moscow whose...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>webNLG</td>\n",
       "      <td>AC_Hotel_Bella_Sky_Copenhagen | architect | 3XN</td>\n",
       "      <td>The architect of the AC Hotel Bella Sky, Copen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6231</th>\n",
       "      <td>webNLG</td>\n",
       "      <td>Aaron_Turner | associatedBand/associatedMusica...</td>\n",
       "      <td>Aaron Turner performs for Mamiffer.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17922</th>\n",
       "      <td>webNLG</td>\n",
       "      <td>Alhambra | powerType | Humphrys,_Tennant_and_D...</td>\n",
       "      <td>The Alhambra has a (London located) Humphrys, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29483</th>\n",
       "      <td>webNLG</td>\n",
       "      <td>GMA_New_Media | product | Mobile_Applications ...</td>\n",
       "      <td>The key person of GMA New Media, in the indust...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24291</th>\n",
       "      <td>webNLG</td>\n",
       "      <td>United_States | demonym | Americans &amp;&amp; United_...</td>\n",
       "      <td>The Atlas ii originates from the US which is l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31230</th>\n",
       "      <td>webNLG</td>\n",
       "      <td>Alhambra | owner | P&amp;O_(company) &amp;&amp; Alhambra |...</td>\n",
       "      <td>The Alhambra, powered by the London based Hump...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5953</th>\n",
       "      <td>webNLG</td>\n",
       "      <td>Alfred_Moore_Scales | battle | Battle_of_Frede...</td>\n",
       "      <td>Alfred Moore Scales fought in the Battle of Fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23307</th>\n",
       "      <td>webNLG</td>\n",
       "      <td>United_States | ethnicGroup | Native_Americans...</td>\n",
       "      <td>Native Americans are an ethnic group within th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336</th>\n",
       "      <td>webNLG</td>\n",
       "      <td>Akeem_Priestley | club | Antigua_GFC</td>\n",
       "      <td>Akeem Priestley plays for Antigua GFC.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32866</th>\n",
       "      <td>webNLG</td>\n",
       "      <td>Hip_hop_music | stylisticOrigin | Disco &amp;&amp; All...</td>\n",
       "      <td>Allen Forrest's genre is Hip Hop music, the st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15366</th>\n",
       "      <td>webNLG</td>\n",
       "      <td>1036_Ganymed | rotationPeriod | 37116.0 &amp;&amp; 103...</td>\n",
       "      <td>1036 Ganymed has a rotational period of 37116....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7419</th>\n",
       "      <td>webNLG</td>\n",
       "      <td>110_Lydia | orbitalPeriod | 142603000.0</td>\n",
       "      <td>110 Lydia has an orbital period of 142603000.0.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15321</th>\n",
       "      <td>webNLG</td>\n",
       "      <td>101_Helena | density | 2.0 (gramPerCubicCentim...</td>\n",
       "      <td>101 Helena has a density of 2.0 grams per cubi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8560</th>\n",
       "      <td>webNLG</td>\n",
       "      <td>Abdulsalami_Abubakar | inOfficeWhileVicePresid...</td>\n",
       "      <td>Abdulsalami Abubakar; served in the Nigerian A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34423</th>\n",
       "      <td>webNLG</td>\n",
       "      <td>AFC_Ajax | numberOfMembers | 53502 &amp;&amp; AFC_Ajax...</td>\n",
       "      <td>The full name of AFC Ajax is \"Amsterdamsche Fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32489</th>\n",
       "      <td>webNLG</td>\n",
       "      <td>Alan_Frew | origin | Canada &amp;&amp; Alan_Frew | bac...</td>\n",
       "      <td>With a background as a solo singer, Alan Frew,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17671</th>\n",
       "      <td>webNLG</td>\n",
       "      <td>AIDAstella | completionDate | 2013-03-11 &amp;&amp; AI...</td>\n",
       "      <td>AIDAstella is 253260.0 millimetres in length a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21035</th>\n",
       "      <td>webNLG</td>\n",
       "      <td>Adam_McQuaid | birthPlace | Charlottetown &amp;&amp; A...</td>\n",
       "      <td>Adam McQuaid was born in 1986, in Charlottetown.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6577</th>\n",
       "      <td>webNLG</td>\n",
       "      <td>Anders_Osborne | associatedBand/associatedMusi...</td>\n",
       "      <td>Anders Osborne has worked with the band Galactic.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22382</th>\n",
       "      <td>webNLG</td>\n",
       "      <td>Alberto_Teisaire | deathPlace | Buenos_Aires &amp;...</td>\n",
       "      <td>A member of the Justicialist Party, Alberto Te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1367</th>\n",
       "      <td>webNLG</td>\n",
       "      <td>Al-Wakrah_Sport_Club | position | Qatar_Stars_...</td>\n",
       "      <td>Al-Wakrah Sport Club position is in the Qatar ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28059</th>\n",
       "      <td>webNLG</td>\n",
       "      <td>Birmingham | leader | Liberal_Democrats &amp;&amp; 103...</td>\n",
       "      <td>The Liberal Democrats lead Birmingham, home to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       prefix                                         input_text  \\\n",
       "21864  webNLG  Bananaman | starring | Tim_Brooke-Taylor && Ba...   \n",
       "29613  webNLG  14th_New_Jersey_Volunteer_Infantry_Monument | ...   \n",
       "32543  webNLG  Aleksandra_Kovač | associatedBand/associatedMu...   \n",
       "30958  webNLG  AIDAstella | christeningDate | 2013-03-16 && A...   \n",
       "8431   webNLG  11264_Claudiomaccone | averageSpeed | 18.29 (k...   \n",
       "4593   webNLG                Serie_A | champions | Juventus_F.C.   \n",
       "19044  webNLG  Albennie_Jones | genre | Jazz && Albennie_Jone...   \n",
       "21172  webNLG  Akeem_Priestley | club | Sheikh_Russel_KC && A...   \n",
       "34426  webNLG  AFC_Ajax_(amateurs) | ground | Sportpark_De_To...   \n",
       "3663   webNLG        Antares_(rocket) | finalFlight | 2014-07-13   \n",
       "27404  webNLG  Elliot_See | status | \"Deceased\" && Elliot_See...   \n",
       "25003  webNLG  Alligator_Records | location | Chicago && Ande...   \n",
       "5315   webNLG                   Ícolo_e_Bengo | country | Angola   \n",
       "49     webNLG                 Arem-arem | course | \"Main course\"   \n",
       "27736  webNLG  300_North_LaSalle | location | Chicago && Chic...   \n",
       "3130   webNLG                Aenir | followedBy | Above_the_Veil   \n",
       "7474   webNLG  103_Colmore_Row | architect | John_Madin && 10...   \n",
       "34687  webNLG  Abner_(footballer) | club | Real_Madrid_Castil...   \n",
       "14714  webNLG  3Arena | owner | Live_Nation_Entertainment && ...   \n",
       "24395  webNLG  Acta_Palaeontologica_Polonica | issnNumber | \"...   \n",
       "24444  webNLG  English_language | spokenIn | Great_Britain &&...   \n",
       "11710  webNLG  English_language | spokenIn | Great_Britain &&...   \n",
       "16967  webNLG  Indiana | capital | Indianapolis && Alexandria...   \n",
       "8076   webNLG  Duncan_Rouleau | nationality | Americans && Ba...   \n",
       "34657  webNLG  Abel_Hernández | club | Peñarol && Peñarol | m...   \n",
       "25322  webNLG  Arrabbiata_sauce | country | Italy && Italy | ...   \n",
       "10658  webNLG  Saranac_Lake,_New_York | isPartOf | Harrietsto...   \n",
       "30968  webNLG  AIDAstella | maidenVoyage | 2013-03-17 && AIDA...   \n",
       "18583  webNLG  Administrative_Science_Quarterly | abbreviatio...   \n",
       "1520   webNLG             Aleksandre_Guruli | club | US_Boulogne   \n",
       "...       ...                                                ...   \n",
       "18478  webNLG  A_Severed_Wasp | language | English_language &...   \n",
       "32719  webNLG  Allen_Forrest | genre | Rhythm_and_blues && Al...   \n",
       "18562  webNLG  Acta_Palaeontologica_Polonica | publisher | Po...   \n",
       "15120  webNLG  Bibbo_Bibbowski | creator | Jerry_Ordway && Bi...   \n",
       "34263  webNLG  A.D._Isidro_Metapán | ground | \"Metapán, El Sa...   \n",
       "33923  webNLG  Elliot_See | almaMater | University_of_Texas_a...   \n",
       "2336   webNLG  Richland_Township,_Madison_County,_Indiana | c...   \n",
       "21263  webNLG  Aleksandr_Chumakov | deathPlace | Moscow && Mo...   \n",
       "732    webNLG    AC_Hotel_Bella_Sky_Copenhagen | architect | 3XN   \n",
       "6231   webNLG  Aaron_Turner | associatedBand/associatedMusica...   \n",
       "17922  webNLG  Alhambra | powerType | Humphrys,_Tennant_and_D...   \n",
       "29483  webNLG  GMA_New_Media | product | Mobile_Applications ...   \n",
       "24291  webNLG  United_States | demonym | Americans && United_...   \n",
       "31230  webNLG  Alhambra | owner | P&O_(company) && Alhambra |...   \n",
       "5953   webNLG  Alfred_Moore_Scales | battle | Battle_of_Frede...   \n",
       "23307  webNLG  United_States | ethnicGroup | Native_Americans...   \n",
       "1336   webNLG               Akeem_Priestley | club | Antigua_GFC   \n",
       "32866  webNLG  Hip_hop_music | stylisticOrigin | Disco && All...   \n",
       "15366  webNLG  1036_Ganymed | rotationPeriod | 37116.0 && 103...   \n",
       "7419   webNLG            110_Lydia | orbitalPeriod | 142603000.0   \n",
       "15321  webNLG  101_Helena | density | 2.0 (gramPerCubicCentim...   \n",
       "8560   webNLG  Abdulsalami_Abubakar | inOfficeWhileVicePresid...   \n",
       "34423  webNLG  AFC_Ajax | numberOfMembers | 53502 && AFC_Ajax...   \n",
       "32489  webNLG  Alan_Frew | origin | Canada && Alan_Frew | bac...   \n",
       "17671  webNLG  AIDAstella | completionDate | 2013-03-11 && AI...   \n",
       "21035  webNLG  Adam_McQuaid | birthPlace | Charlottetown && A...   \n",
       "6577   webNLG  Anders_Osborne | associatedBand/associatedMusi...   \n",
       "22382  webNLG  Alberto_Teisaire | deathPlace | Buenos_Aires &...   \n",
       "1367   webNLG  Al-Wakrah_Sport_Club | position | Qatar_Stars_...   \n",
       "28059  webNLG  Birmingham | leader | Liberal_Democrats && 103...   \n",
       "\n",
       "                                             target_text  \n",
       "21864  The BBC began broadcasting Bananaman on 10/03/...  \n",
       "29613  The 14th New Jersey Volunteer Infantry Monumen...  \n",
       "32543  Aleksandra Kovac has the musical genre of pop ...  \n",
       "30958  The christening date of AIDAstella is 2013-03-...  \n",
       "8431   Nikolai Chernykh discovered 11264 Claudiomacco...  \n",
       "4593      Juventus F.C. are former champions of Serie A.  \n",
       "19044  Albennie Jones is a solo singer and performs j...  \n",
       "21172  Akeem Priestley's club is Harbour View F.C and...  \n",
       "34426  AFC Ajax (amateurs)'s ground is Sportpark De T...  \n",
       "3663   The final flight for the rocket Antares was on...  \n",
       "27404  The American test pilot Elliot See was born in...  \n",
       "25003  Anders Osborne is a rock musician associated w...  \n",
       "5315                         Ícolo e Bengo is in Angola.  \n",
       "49                           Arem arem is a main course.  \n",
       "27736  Located in the United States is 300 North LaSa...  \n",
       "3130   The book Aenir was followed up by Above the Veil.  \n",
       "7474   John Madin was the architect of 103 Colmore Ro...  \n",
       "34687  The footballer Abner was born on 30/05/1996 an...  \n",
       "14714  The owner of 3Arena, located at North Wall, Du...  \n",
       "24395  Acta Palaeontologica Polonica (abbrv. Acta Pal...  \n",
       "24444  The United States, whose capital is Washington...  \n",
       "11710  A Loyal Character Dancer is published in the U...  \n",
       "16967  Alexandria is located in Indiana where Indiana...  \n",
       "8076   Baymax is a character in the film Big Hero 6 w...  \n",
       "34657  Abel Hernández has played for U.S. Città di Pa...  \n",
       "25322  Italians are from Italy where Pietro Grasso is...  \n",
       "10658  Adirondack Regional Airport serves the city of...  \n",
       "30968  The AIDAstella was christened on 16th of March...  \n",
       "18583  The ISSN number for Administrative Science Qua...  \n",
       "1520           Aleksandre Guruli played for US Boulogne.  \n",
       "...                                                  ...  \n",
       "18478  A Severed Wasp originates from the United Stat...  \n",
       "32719  Born in Fort Campbell, Allen Forrest, is a sol...  \n",
       "18562  Acta Palaeontologica Polonica was published by...  \n",
       "15120  Bo Bibbowski is often called Bibbo and was cre...  \n",
       "34263  Asociacion Deportiva (abbreviated to A.D. Isid...  \n",
       "33923  Elliot See, who was born in Dallas, attended t...  \n",
       "2336   Richland Township, in Madison County, Indiana ...  \n",
       "21263  Aleksandr Chumakov passed away in Moscow whose...  \n",
       "732    The architect of the AC Hotel Bella Sky, Copen...  \n",
       "6231                 Aaron Turner performs for Mamiffer.  \n",
       "17922  The Alhambra has a (London located) Humphrys, ...  \n",
       "29483  The key person of GMA New Media, in the indust...  \n",
       "24291  The Atlas ii originates from the US which is l...  \n",
       "31230  The Alhambra, powered by the London based Hump...  \n",
       "5953   Alfred Moore Scales fought in the Battle of Fr...  \n",
       "23307  Native Americans are an ethnic group within th...  \n",
       "1336              Akeem Priestley plays for Antigua GFC.  \n",
       "32866  Allen Forrest's genre is Hip Hop music, the st...  \n",
       "15366  1036 Ganymed has a rotational period of 37116....  \n",
       "7419     110 Lydia has an orbital period of 142603000.0.  \n",
       "15321  101 Helena has a density of 2.0 grams per cubi...  \n",
       "8560   Abdulsalami Abubakar; served in the Nigerian A...  \n",
       "34423  The full name of AFC Ajax is \"Amsterdamsche Fo...  \n",
       "32489  With a background as a solo singer, Alan Frew,...  \n",
       "17671  AIDAstella is 253260.0 millimetres in length a...  \n",
       "21035   Adam McQuaid was born in 1986, in Charlottetown.  \n",
       "6577   Anders Osborne has worked with the band Galactic.  \n",
       "22382  A member of the Justicialist Party, Alberto Te...  \n",
       "1367   Al-Wakrah Sport Club position is in the Qatar ...  \n",
       "28059  The Liberal Democrats lead Birmingham, home to...  \n",
       "\n",
       "[35000 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on the CPU\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    dev = torch.device(\"cuda:0\")\n",
    "    print(\"Running on the GPU\")\n",
    "else:\n",
    "    dev = torch.device(\"cpu\")\n",
    "    print(\"Running on the CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 768)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (8): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (9): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (10): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (11): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (8): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (9): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (10): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (11): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained('t5-base')\n",
    "model = T5ForConditionalGeneration.from_pretrained('t5-base',\n",
    "                                             return_dict=True)\n",
    "#moving the model to GPU\n",
    "model.to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adafactor(model.parameters(),lr=1e-3,\n",
    "                      eps=(1e-30, 1e-3),\n",
    "                      clip_threshold=1.0,\n",
    "                      decay_rate=-0.8,\n",
    "                      beta1=None,\n",
    "                      weight_decay=0.0,\n",
    "                      relative_step=False,\n",
    "                      scale_parameter=False,\n",
    "                      warmup_init=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML, display\n",
    "def progress(loss,value, max=100):\n",
    "    return HTML(\"\"\" Batch loss :{loss}\n",
    "      <progress    \n",
    "value='{value}'max='{max}',style='width: 100%'>{value}\n",
    "      </progress>\n",
    "             \"\"\".format(loss=loss,value=value, max=max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running epoch: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       " Batch loss :0.9637755155563354\n",
       "      <progress    \n",
       "value='7'max='4376',style='width: 100%'>7\n",
       "      </progress>\n",
       "             "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/.local/lib/python3.8/site-packages/transformers/models/t5/tokenization_t5.py:185: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
      "  warnings.warn(\n",
      "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-e28f7efd4a23>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;31m# calculating the gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;31m#updating the params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \"\"\"\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Sets the module in training mode\n",
    "model.train()\n",
    "num_of_epochs = 3\n",
    "\n",
    "loss_per_10_steps=[]\n",
    "for epoch in range(1,num_of_epochs+1):\n",
    "    print('Running epoch: {}'.format(epoch))\n",
    "  \n",
    "    running_loss=0\n",
    "\n",
    "    out = display(progress(1, num_of_batches+1), display_id=True)\n",
    "    for i in range(num_of_batches):\n",
    "        inputbatch=[]\n",
    "        labelbatch=[]\n",
    "        new_df=train_df[i*batch_size:i*batch_size+batch_size]\n",
    "        for indx,row in new_df.iterrows():\n",
    "            input = 'WebNLG: '+row['input_text']+'</s>' \n",
    "            labels = row['target_text']+'</s>'   \n",
    "            inputbatch.append(input)\n",
    "            labelbatch.append(labels)\n",
    "        inputbatch=tokenizer.batch_encode_plus(inputbatch,padding=True,max_length=400,return_tensors='pt')[\"input_ids\"]\n",
    "        labelbatch=tokenizer.batch_encode_plus(labelbatch,padding=True,max_length=400,return_tensors=\"pt\") [\"input_ids\"]\n",
    "        inputbatch=inputbatch.to(dev)\n",
    "        labelbatch=labelbatch.to(dev)\n",
    "\n",
    "        # clear out the gradients of all Variables \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward propogation\n",
    "        outputs = model(input_ids=inputbatch, labels=labelbatch)\n",
    "        loss = outputs.loss\n",
    "        loss_num=loss.item()\n",
    "        logits = outputs.logits\n",
    "        running_loss+=loss_num\n",
    "        if i%10 ==0:      \n",
    "            loss_per_10_steps.append(loss_num)\n",
    "        out.update(progress(loss_num,i, num_of_batches+1))\n",
    "\n",
    "        # calculating the gradients\n",
    "        loss.backward()\n",
    "\n",
    "        #updating the params\n",
    "        optimizer.step()\n",
    "    \n",
    "    running_loss=running_loss/int(num_of_batches)\n",
    "    print('Epoch: {} , Running loss: {}'.format(epoch,running_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(),'trained_model/pytorch_model.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained('t5-base')\n",
    "model = T5ForConditionalGeneration.from_pretrained('trained_model', \n",
    "                                                return_dict=True)\n",
    "import re\n",
    "\n",
    "def generate(text):\n",
    "    texts = text.split(\".\")\n",
    "    result = \"\"\n",
    "    for txt in texts:\n",
    "        model.eval()\n",
    "        input_ids = tokenizer.encode(\"WebNLG:{} </s>\".format(txt), \n",
    "                                   return_tensors=\"pt\")  \n",
    "        outputs = model.generate(input_ids)\n",
    "        result += tokenizer.decode(outputs[0])\n",
    "    result = re.sub('<pad>|</s>',\"\",result)\n",
    "    return result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
